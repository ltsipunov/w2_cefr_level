{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40708282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TABLEAU_COLORS as tabcols\n",
    "\n",
    "from sklearn.linear_model  import LogisticRegression,LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import r2_score,accuracy_score,recall_score,precision_score,f1_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7000bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  movies_params  import feature_cols,target_col\n",
    "rnd = 499\n",
    "np.random.seed(rnd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d14aae",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e7bc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  290 non-null    int64  \n",
      " 1   movie       290 non-null    object \n",
      " 2   B2_freq     266 non-null    float64\n",
      " 3   A2_freq     266 non-null    float64\n",
      " 4   A1_freq     266 non-null    float64\n",
      " 5   B1_freq     266 non-null    float64\n",
      " 6   C1_freq     266 non-null    float64\n",
      " 7   B2_rate     266 non-null    float64\n",
      " 8   A2_rate     266 non-null    float64\n",
      " 9   A1_rate     266 non-null    float64\n",
      " 10  B1_rate     266 non-null    float64\n",
      " 11  C1_rate     266 non-null    float64\n",
      " 12  qty         266 non-null    float64\n",
      " 13  ne          266 non-null    float64\n",
      " 14  avg_length  266 non-null    float64\n",
      " 15  level       241 non-null    object \n",
      "dtypes: float64(13), int64(1), object(2)\n",
      "memory usage: 36.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/movies.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd04601",
   "metadata": {},
   "source": [
    "Собранный датасет  экспортируются как full outer join, что бы можно было оценить его качество и количество промахов.   \n",
    "Но здесь незаполненнные поля исправить неоткуда, поэтому я просто удаляю ошибки подготовки   \n",
    "Также удаляю колонки, не нужные в моделировании (в это версии только названия фильмов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc2f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 217 entries, 0 to 265\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  217 non-null    int64  \n",
      " 1   movie       217 non-null    object \n",
      " 2   B2_freq     217 non-null    float64\n",
      " 3   A2_freq     217 non-null    float64\n",
      " 4   A1_freq     217 non-null    float64\n",
      " 5   B1_freq     217 non-null    float64\n",
      " 6   C1_freq     217 non-null    float64\n",
      " 7   B2_rate     217 non-null    float64\n",
      " 8   A2_rate     217 non-null    float64\n",
      " 9   A1_rate     217 non-null    float64\n",
      " 10  B1_rate     217 non-null    float64\n",
      " 11  C1_rate     217 non-null    float64\n",
      " 12  qty         217 non-null    float64\n",
      " 13  ne          217 non-null    float64\n",
      " 14  avg_length  217 non-null    float64\n",
      " 15  level       217 non-null    object \n",
      "dtypes: float64(13), int64(1), object(2)\n",
      "memory usage: 28.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[~df.isna().any(axis=1)]\n",
    "drop_cols = [c for c in df.columns if c not in feature_cols+[target_col]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dcad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df.drop(drop_cols,axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8de2e",
   "metadata": {},
   "source": [
    "### Предварительный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e832a1",
   "metadata": {},
   "source": [
    "Имена признаков записываются на этапе подготовки и сохраняются в передаточном файле, прочитаем прочитаем их оттуда  проведем разбиение на тренировочный и тестовый наборы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f4c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_cols\n",
    "y = target_col\n",
    "tr_X,te_X,tr_y,te_y= train_test_split(dx[X],dx[y],test_size = 0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8647d",
   "metadata": {},
   "source": [
    "Корреляций нет "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbb3b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_freq</th>\n",
       "      <th>A2_freq</th>\n",
       "      <th>B1_freq</th>\n",
       "      <th>B2_freq</th>\n",
       "      <th>C1_freq</th>\n",
       "      <th>A1_rate</th>\n",
       "      <th>A2_rate</th>\n",
       "      <th>B1_rate</th>\n",
       "      <th>B2_rate</th>\n",
       "      <th>C1_rate</th>\n",
       "      <th>qty</th>\n",
       "      <th>ne</th>\n",
       "      <th>avg_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1_freq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087461</td>\n",
       "      <td>-0.182791</td>\n",
       "      <td>-0.446949</td>\n",
       "      <td>-0.214703</td>\n",
       "      <td>0.565131</td>\n",
       "      <td>0.236604</td>\n",
       "      <td>0.108092</td>\n",
       "      <td>-0.244977</td>\n",
       "      <td>-0.336829</td>\n",
       "      <td>0.196918</td>\n",
       "      <td>-0.291314</td>\n",
       "      <td>-0.497754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_freq</th>\n",
       "      <td>-0.087461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>0.112940</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>-0.109032</td>\n",
       "      <td>0.451949</td>\n",
       "      <td>0.068684</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>-0.090086</td>\n",
       "      <td>-0.088883</td>\n",
       "      <td>0.356207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1_freq</th>\n",
       "      <td>-0.182791</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.512593</td>\n",
       "      <td>0.441599</td>\n",
       "      <td>-0.059411</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>0.662017</td>\n",
       "      <td>0.492660</td>\n",
       "      <td>0.431306</td>\n",
       "      <td>-0.287107</td>\n",
       "      <td>-0.251325</td>\n",
       "      <td>0.375182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2_freq</th>\n",
       "      <td>-0.446949</td>\n",
       "      <td>0.112940</td>\n",
       "      <td>0.512593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.304681</td>\n",
       "      <td>-0.165669</td>\n",
       "      <td>0.141117</td>\n",
       "      <td>0.341146</td>\n",
       "      <td>0.793290</td>\n",
       "      <td>0.402090</td>\n",
       "      <td>-0.407516</td>\n",
       "      <td>-0.129733</td>\n",
       "      <td>0.547415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1_freq</th>\n",
       "      <td>-0.214703</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.441599</td>\n",
       "      <td>0.304681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033921</td>\n",
       "      <td>0.050469</td>\n",
       "      <td>0.377693</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>-0.247245</td>\n",
       "      <td>-0.155699</td>\n",
       "      <td>0.219043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1_rate</th>\n",
       "      <td>0.565131</td>\n",
       "      <td>-0.109032</td>\n",
       "      <td>-0.059411</td>\n",
       "      <td>-0.165669</td>\n",
       "      <td>-0.033921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491045</td>\n",
       "      <td>0.168329</td>\n",
       "      <td>-0.143928</td>\n",
       "      <td>-0.386166</td>\n",
       "      <td>-0.476154</td>\n",
       "      <td>-0.192351</td>\n",
       "      <td>-0.243745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_rate</th>\n",
       "      <td>0.236604</td>\n",
       "      <td>0.451949</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>0.141117</td>\n",
       "      <td>0.050469</td>\n",
       "      <td>0.491045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266298</td>\n",
       "      <td>0.207458</td>\n",
       "      <td>-0.106664</td>\n",
       "      <td>-0.396677</td>\n",
       "      <td>-0.330760</td>\n",
       "      <td>0.066501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1_rate</th>\n",
       "      <td>0.108092</td>\n",
       "      <td>0.068684</td>\n",
       "      <td>0.662017</td>\n",
       "      <td>0.341146</td>\n",
       "      <td>0.377693</td>\n",
       "      <td>0.168329</td>\n",
       "      <td>0.266298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>0.307941</td>\n",
       "      <td>-0.198587</td>\n",
       "      <td>-0.311758</td>\n",
       "      <td>0.063990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2_rate</th>\n",
       "      <td>-0.244977</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>0.492660</td>\n",
       "      <td>0.793290</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>-0.143928</td>\n",
       "      <td>0.207458</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477766</td>\n",
       "      <td>-0.245270</td>\n",
       "      <td>-0.203506</td>\n",
       "      <td>0.391485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1_rate</th>\n",
       "      <td>-0.336829</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.431306</td>\n",
       "      <td>0.402090</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>-0.386166</td>\n",
       "      <td>-0.106664</td>\n",
       "      <td>0.307941</td>\n",
       "      <td>0.477766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006391</td>\n",
       "      <td>-0.148421</td>\n",
       "      <td>0.221285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qty</th>\n",
       "      <td>0.196918</td>\n",
       "      <td>-0.090086</td>\n",
       "      <td>-0.287107</td>\n",
       "      <td>-0.407516</td>\n",
       "      <td>-0.247245</td>\n",
       "      <td>-0.476154</td>\n",
       "      <td>-0.396677</td>\n",
       "      <td>-0.198587</td>\n",
       "      <td>-0.245270</td>\n",
       "      <td>-0.006391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>-0.572621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ne</th>\n",
       "      <td>-0.291314</td>\n",
       "      <td>-0.088883</td>\n",
       "      <td>-0.251325</td>\n",
       "      <td>-0.129733</td>\n",
       "      <td>-0.155699</td>\n",
       "      <td>-0.192351</td>\n",
       "      <td>-0.330760</td>\n",
       "      <td>-0.311758</td>\n",
       "      <td>-0.203506</td>\n",
       "      <td>-0.148421</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_length</th>\n",
       "      <td>-0.497754</td>\n",
       "      <td>0.356207</td>\n",
       "      <td>0.375182</td>\n",
       "      <td>0.547415</td>\n",
       "      <td>0.219043</td>\n",
       "      <td>-0.243745</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>0.391485</td>\n",
       "      <td>0.221285</td>\n",
       "      <td>-0.572621</td>\n",
       "      <td>0.126735</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             A1_freq   A2_freq   B1_freq   B2_freq   C1_freq   A1_rate  \\\n",
       "A1_freq     1.000000 -0.087461 -0.182791 -0.446949 -0.214703  0.565131   \n",
       "A2_freq    -0.087461  1.000000  0.054099  0.112940  0.002246 -0.109032   \n",
       "B1_freq    -0.182791  0.054099  1.000000  0.512593  0.441599 -0.059411   \n",
       "B2_freq    -0.446949  0.112940  0.512593  1.000000  0.304681 -0.165669   \n",
       "C1_freq    -0.214703  0.002246  0.441599  0.304681  1.000000 -0.033921   \n",
       "A1_rate     0.565131 -0.109032 -0.059411 -0.165669 -0.033921  1.000000   \n",
       "A2_rate     0.236604  0.451949  0.097884  0.141117  0.050469  0.491045   \n",
       "B1_rate     0.108092  0.068684  0.662017  0.341146  0.377693  0.168329   \n",
       "B2_rate    -0.244977  0.119093  0.492660  0.793290  0.366575 -0.143928   \n",
       "C1_rate    -0.336829  0.041527  0.431306  0.402090  0.650369 -0.386166   \n",
       "qty         0.196918 -0.090086 -0.287107 -0.407516 -0.247245 -0.476154   \n",
       "ne         -0.291314 -0.088883 -0.251325 -0.129733 -0.155699 -0.192351   \n",
       "avg_length -0.497754  0.356207  0.375182  0.547415  0.219043 -0.243745   \n",
       "\n",
       "             A2_rate   B1_rate   B2_rate   C1_rate       qty        ne  \\\n",
       "A1_freq     0.236604  0.108092 -0.244977 -0.336829  0.196918 -0.291314   \n",
       "A2_freq     0.451949  0.068684  0.119093  0.041527 -0.090086 -0.088883   \n",
       "B1_freq     0.097884  0.662017  0.492660  0.431306 -0.287107 -0.251325   \n",
       "B2_freq     0.141117  0.341146  0.793290  0.402090 -0.407516 -0.129733   \n",
       "C1_freq     0.050469  0.377693  0.366575  0.650369 -0.247245 -0.155699   \n",
       "A1_rate     0.491045  0.168329 -0.143928 -0.386166 -0.476154 -0.192351   \n",
       "A2_rate     1.000000  0.266298  0.207458 -0.106664 -0.396677 -0.330760   \n",
       "B1_rate     0.266298  1.000000  0.392710  0.307941 -0.198587 -0.311758   \n",
       "B2_rate     0.207458  0.392710  1.000000  0.477766 -0.245270 -0.203506   \n",
       "C1_rate    -0.106664  0.307941  0.477766  1.000000 -0.006391 -0.148421   \n",
       "qty        -0.396677 -0.198587 -0.245270 -0.006391  1.000000  0.012127   \n",
       "ne         -0.330760 -0.311758 -0.203506 -0.148421  0.012127  1.000000   \n",
       "avg_length  0.066501  0.063990  0.391485  0.221285 -0.572621  0.126735   \n",
       "\n",
       "            avg_length  \n",
       "A1_freq      -0.497754  \n",
       "A2_freq       0.356207  \n",
       "B1_freq       0.375182  \n",
       "B2_freq       0.547415  \n",
       "C1_freq       0.219043  \n",
       "A1_rate      -0.243745  \n",
       "A2_rate       0.066501  \n",
       "B1_rate       0.063990  \n",
       "B2_rate       0.391485  \n",
       "C1_rate       0.221285  \n",
       "qty          -0.572621  \n",
       "ne            0.126735  \n",
       "avg_length    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[X].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945596ab",
   "metadata": {},
   "source": [
    "Посмотрим зависимость средних по категориям.  \n",
    "Есть ожидаемый прогресс с ростом категории, но возможно он очень слабый для хороших предсказаний  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc40457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_freq</th>\n",
       "      <th>A2_freq</th>\n",
       "      <th>B1_freq</th>\n",
       "      <th>B2_freq</th>\n",
       "      <th>C1_freq</th>\n",
       "      <th>A1_rate</th>\n",
       "      <th>A2_rate</th>\n",
       "      <th>B1_rate</th>\n",
       "      <th>B2_rate</th>\n",
       "      <th>C1_rate</th>\n",
       "      <th>qty</th>\n",
       "      <th>ne</th>\n",
       "      <th>avg_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>0.325128</td>\n",
       "      <td>0.132586</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.071233</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>0.227247</td>\n",
       "      <td>0.146506</td>\n",
       "      <td>0.092614</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>3886.083333</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>1.963889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.328667</td>\n",
       "      <td>0.137998</td>\n",
       "      <td>0.075841</td>\n",
       "      <td>0.078167</td>\n",
       "      <td>0.031433</td>\n",
       "      <td>0.224656</td>\n",
       "      <td>0.144795</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.103925</td>\n",
       "      <td>0.039846</td>\n",
       "      <td>3997.688525</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>2.195082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.330957</td>\n",
       "      <td>0.125207</td>\n",
       "      <td>0.081584</td>\n",
       "      <td>0.083892</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.235098</td>\n",
       "      <td>0.146889</td>\n",
       "      <td>0.100888</td>\n",
       "      <td>0.109988</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>3612.608247</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>2.059794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>0.325322</td>\n",
       "      <td>0.133317</td>\n",
       "      <td>0.082909</td>\n",
       "      <td>0.083539</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.231361</td>\n",
       "      <td>0.148717</td>\n",
       "      <td>0.105778</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.045048</td>\n",
       "      <td>3305.739130</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>2.239130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A1_freq   A2_freq   B1_freq   B2_freq   C1_freq   A1_rate   A2_rate  \\\n",
       "level                                                                         \n",
       "A2     0.325128  0.132586  0.071086  0.071233  0.030194  0.227247  0.146506   \n",
       "B1     0.328667  0.137998  0.075841  0.078167  0.031433  0.224656  0.144795   \n",
       "B2     0.330957  0.125207  0.081584  0.083892  0.035971  0.235098  0.146889   \n",
       "C1     0.325322  0.133317  0.082909  0.083539  0.040643  0.231361  0.148717   \n",
       "\n",
       "        B1_rate   B2_rate   C1_rate          qty        ne  avg_length  \n",
       "level                                                                   \n",
       "A2     0.092614  0.097700  0.041050  3886.083333  0.011339    1.963889  \n",
       "B1     0.095648  0.103925  0.039846  3997.688525  0.010974    2.195082  \n",
       "B2     0.100888  0.109988  0.044156  3612.608247  0.009806    2.059794  \n",
       "C1     0.105778  0.111000  0.045048  3305.739130  0.012826    2.239130  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('level')[X].agg(pd.Series.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83b8aa",
   "metadata": {},
   "source": [
    "Следующий запрос показывает долю успешно категоризированных  слов по фильмам каждой категории   \n",
    "Эта доля колеблется от 50 до 75 % , так что здесь есть серьёзные утечки, с которыми нужно работать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa11adb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>0.5122</td>\n",
       "      <td>0.7316</td>\n",
       "      <td>0.630228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.652107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.657610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>0.5587</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.665730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min     max      mean\n",
       "level                          \n",
       "A2     0.5122  0.7316  0.630228\n",
       "B1     0.5022  0.7596  0.652107\n",
       "B2     0.5635  0.7223  0.657610\n",
       "C1     0.5587  0.7083  0.665730"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sum_freq']=df.apply(lambda r: sum([r[c] for c in feature_cols if c[-4:]=='freq' ]),axis=1)\n",
    "df.groupby('level').sum_freq.agg([pd.Series.min,pd.Series.max,pd.Series.mean])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2da4d1",
   "metadata": {},
   "source": [
    "Вероятности для пробной классификации показывют очень плохое обнаружение фильмов класса C1  \n",
    "Найден только 1 объект из 6, причем у 4 промахов вероятности определены как меньше 20%   \n",
    "Похоже на неудачный выбор признаков для обнаружения этой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b973b505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>pr</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.030</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.025</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.020</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.080</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.235</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.035</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.090</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.165</td>\n",
       "      <td>B2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.105</td>\n",
       "      <td>B1</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.020</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.170</td>\n",
       "      <td>B2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.324167</td>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.040</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.030</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.194583</td>\n",
       "      <td>0.595417</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.030</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.240</td>\n",
       "      <td>B2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>B2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.180</td>\n",
       "      <td>B2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.120</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.080</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.005</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.055</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.209167</td>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.060</td>\n",
       "      <td>B1</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.020</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.145</td>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.325</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.355</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.025</td>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.015</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.315</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.244167</td>\n",
       "      <td>0.540833</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.010</td>\n",
       "      <td>B1</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.200</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.081667</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.110</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.125</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.005</td>\n",
       "      <td>B1</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.050</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.250</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.045</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.100</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.010</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.185833</td>\n",
       "      <td>0.274167</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.410</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.788333</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.010</td>\n",
       "      <td>B1</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.030</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.319583</td>\n",
       "      <td>0.475417</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.040</td>\n",
       "      <td>B1</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A2        B1     B2     C1  pr level\n",
       "110  0.165000  0.145000  0.660  0.030  B2    B2\n",
       "12   0.090000  0.610000  0.275  0.025  B1    B1\n",
       "1    0.425000  0.220000  0.335  0.020  A2    A2\n",
       "20   0.200000  0.590000  0.130  0.080  B1    B1\n",
       "178  0.080000  0.085000  0.600  0.235  B2    B2\n",
       "16   0.045000  0.775000  0.145  0.035  B1    B1\n",
       "114  0.000000  0.005000  0.905  0.090  B2    B2\n",
       "142  0.160000  0.115000  0.560  0.165  B2    C1\n",
       "129  0.285000  0.305000  0.305  0.105  B1    B2\n",
       "206  0.215000  0.440000  0.325  0.020  B1    B1\n",
       "157  0.150000  0.145000  0.535  0.170  B2    A2\n",
       "248  0.324167  0.405833  0.230  0.040  B1    B1\n",
       "161  0.120000  0.295000  0.555  0.030  B2    B1\n",
       "216  0.194583  0.595417  0.180  0.030  B1    C1\n",
       "141  0.020000  0.055000  0.685  0.240  B2    C1\n",
       "215  0.140000  0.205000  0.485  0.170  B2    C1\n",
       "140  0.045000  0.195000  0.580  0.180  B2    C1\n",
       "99   0.005000  0.025000  0.850  0.120  B2    B2\n",
       "33   0.020000  0.015000  0.885  0.080  B2    B2\n",
       "22   0.095000  0.395000  0.505  0.005  B2    B1\n",
       "173  0.055000  0.210000  0.680  0.055  B2    B1\n",
       "192  0.209167  0.405833  0.325  0.060  B1    A2\n",
       "171  0.465000  0.400000  0.115  0.020  A2    B1\n",
       "68   0.380000  0.210000  0.265  0.145  A2    B2\n",
       "111  0.080000  0.175000  0.420  0.325  B2    B2\n",
       "260  0.193333  0.346667  0.460  0.000  B2    B2\n",
       "217  0.075000  0.085000  0.485  0.355  B2    B1\n",
       "159  0.370000  0.280000  0.325  0.025  A2    B2\n",
       "35   0.030000  0.045000  0.910  0.015  B2    B2\n",
       "81   0.070000  0.070000  0.545  0.315  B2    B2\n",
       "181  0.244167  0.540833  0.205  0.010  B1    A2\n",
       "152  0.135000  0.140000  0.525  0.200  B2    B2\n",
       "6    0.081667  0.258333  0.550  0.110  B2    B1\n",
       "147  0.150000  0.355000  0.370  0.125  B2    B1\n",
       "184  0.247500  0.577500  0.170  0.005  B1    A2\n",
       "7    0.253000  0.602000  0.095  0.050  B1    B1\n",
       "172  0.225000  0.285000  0.240  0.250  B1    B1\n",
       "97   0.010000  0.020000  0.925  0.045  B2    B2\n",
       "80   0.080000  0.080000  0.740  0.100  B2    B2\n",
       "107  0.010000  0.075000  0.905  0.010  B2    B2\n",
       "134  0.185833  0.274167  0.130  0.410  C1    C1\n",
       "228  0.051667  0.788333  0.150  0.010  B1    B2\n",
       "104  0.040000  0.125000  0.805  0.030  B2    B2\n",
       "245  0.319583  0.475417  0.165  0.040  B1    A2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200,max_depth=100,class_weight=None,max_features=None)\n",
    "model.fit(tr_X,tr_y)\n",
    "pb = pd.DataFrame( model.predict_proba(te_X),index= te_y.index,columns= model.classes_ )\n",
    "pr = pd.Series( model.predict(te_X),index= te_y.index,name='pr' )\n",
    "pb.join(pr).join(te_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cf4f2",
   "metadata": {},
   "source": [
    "Бинарная классификация плохо работает на крайних категориях, но показывает  неплохие результаты пр иделении пополам,  тогда  возможно имеет смысл провести две последовательных таких классификации, тогда общую ошибку я ожидаю на уровне квадрата одной бинарной т.е где-то .55   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b91d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.1333\t pre: 0.5\trec: 0.0769\t acc: 0.8194\n",
      "f1: 0.4615\t pre: 0.75\trec: 0.3333\t acc: 0.9028\n",
      "f1: 0.8108\t pre: 0.7377\trec: 0.9\t acc: 0.7083\n",
      "f1: 0.7246\t pre: 0.7353\trec: 0.7143\t acc: 0.7361\n"
     ]
    }
   ],
   "source": [
    "df['A2_tar'] = df.level.apply(lambda v: int(v == 'A2') )\n",
    "df['C1_tar'] = df.level.apply(lambda v: int(v == 'C1') )\n",
    "df['B_tar'] = df.level.apply(lambda v: int(v[0] == 'B') )\n",
    "df['AB_tar'] = df.level.apply(lambda v: int( v in ['B1','A2'] ) )\n",
    "\n",
    "for c in ['A2_tar','C1_tar','B_tar','AB_tar']:\n",
    "    r_X,e_X,r_y,e_y = train_test_split(df[X],df[c],test_size = 0.33,shuffle=True,random_state= 5555)\n",
    "    model = RandomForestClassifier(class_weight='balanced',max_features=None)\n",
    "    model.fit(r_X,r_y)\n",
    "    pr = pd.Series(model.predict(e_X),index=e_y.index)\n",
    "    print(f\"f1: {round(f1_score(e_y,pr),4)}\\t pre: {round(precision_score(e_y,pr),4)}\\t\" \n",
    "          f\"rec: {round(recall_score(e_y,pr),4)}\\t acc: {round(accuracy_score(e_y,pr),4)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec7bae",
   "metadata": {},
   "source": [
    "### Кроссвалидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa22c0",
   "metadata": {},
   "source": [
    "Проведем кроссвалидацию моделей на классификаторе LGBM   \n",
    "Сразу скажу, что количество оценщиков, глубина и количество листьев не оказали накакого влияния на результат (до 4 знака), поэтому я их выбросил в итоговом отчете "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929a713f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 0.401321\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.351553\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.322506\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[32]\ttraining's multi_logloss: 0.0389221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting': 'gbdt',\n",
       " 'class_weight': 'balanced',\n",
       " 'learning_rate': 0.3,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 32,\n",
       " 'num_leaves': 99}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "estimator = lgb.LGBMClassifier(max_features=None,objective='multiclass')\n",
    "param_grid = {\n",
    "    'boosting' :['gbdt','dart'],\n",
    "#      'subsample':[.5,.75,.95,1],\n",
    "#      'subsample_freq':[1,2,4],\n",
    "    'learning_rate': [.5,.3,.2,.1,.05,.03,.02,.01,.005,.003,.002],\n",
    "    'n_estimators': [32],\n",
    "    'max_depth':  [8],\n",
    "    'num_leaves': [99],\n",
    "    'class_weight': ['balanced',None]\n",
    "}\n",
    "cbf = [lgb.log_evaluation(50)  ,lgb.early_stopping(5)]\n",
    "gs = GridSearchCV(estimator, param_grid, cv=4,scoring= 'f1_weighted')\n",
    "gs.fit(tr_X, tr_y, eval_set=[(tr_X, tr_y)],callbacks=cbf)\n",
    "gs.cv_results_     \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6799576",
   "metadata": {},
   "source": [
    "### Анализ результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e92eb",
   "metadata": {},
   "source": [
    "Создаем класс для выборки результата и их графического отображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48221f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultPlot:\n",
    "    def __init__(self,x='learning_rate',y='test_score',through=['class_weight'] ,params={}):\n",
    "        self.x = x                   # name of scores mean  along X axes , typically time\n",
    "        self.y = y                   # name of scores mean  along Y axes, typically RMSE\n",
    "        self.through = through\n",
    "        self.params = {\n",
    "            'features': ['n_estimators','learning_rate','max_depth','num_leaves','boosting'],\n",
    "            'means':['test_score'],\n",
    "            'limits': { x: (0,.1), y:(0,1) },\n",
    "            'title' : f\"Dependency of {self.x} and {self.y} \",\n",
    "            'figsize': (10,6),\n",
    "            'markers': ['D'],\n",
    "            'colors' : ['r','b','g'],\n",
    "            'styles' : ['-','--',':','-.']\n",
    "        }\n",
    "        self.params |= params    \n",
    "        \n",
    "        \n",
    "    def  __getattr__(self, k):\n",
    "        if k in self.params:\n",
    "            return ( self.params[k] )\n",
    "\n",
    "    def res_cols(self):\n",
    "        return list( map( lambda s: 'param_'+s, self.features))+list( map( lambda s: 'mean_'+s, self.means) )\n",
    "\n",
    "    def init_dataframe(self):\n",
    "        self.rf = pd.DataFrame( {k:[] for k in self.features+self.means+['label']} )\n",
    "        \n",
    "\n",
    "    def add_result(self,res,label):\n",
    "        f = pd.DataFrame( {k:res[k] for k in self.res_cols()} )\n",
    "        f.columns = self.features+self.means\n",
    "        f['label'] = label\n",
    "        f[self.features] = f[self.features].fillna('None')\n",
    "        f = f[~f.isna().any(axis=1)]\n",
    "        self.rf = pd.concat( [self.rf,f],axis=0 )\n",
    "    \n",
    "    def ax(self):    \n",
    "        return(self.plt.ax)\n",
    "    \n",
    "    def init_plot(self):\n",
    "        self.fig,self.ax = plt.subplots( figsize=self.figsize ) \n",
    "\n",
    "        self.ax.set_title(self.title)\n",
    "        self.ax.set_xlabel(self.x)\n",
    "        self.ax.set_ylabel(self.y)\n",
    "        if self.y in self.limits:\n",
    "            self.ax.set_ylim( self.limits[self.y])\n",
    "\n",
    "    def set_graph_attrs(self):\n",
    "        self.color_map = dict(zip(sorted(p.rf[self.through[0]].unique()),self.colors))\n",
    "        self.style_map = dict(zip(sorted(p.rf[self.through[1]].unique()),self.styles))\n",
    "        \n",
    "    def draw(self):\n",
    "        self.init_plot()\n",
    "        self.set_graph_attrs()\n",
    "        ths = p.rf[self.through].drop_duplicates().sort_values(by = self.through).values.tolist()\n",
    "        \n",
    "        for th in ths:\n",
    "            pf0 = self.rf[(self.rf[self.through].values==th).all(axis=1)]\n",
    "            pf = pf0[[self.x,self.y]]\n",
    "            self.ax.plot(pf[self.x],pf[self.y],\n",
    "                         c=self.color_map[th[0]],ls=self.style_map[th[1]] ,alpha=.75,\n",
    "                         label = ', '.join(th) )\n",
    "        self.ax.legend(title = ' & '.join(self.through))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4afbbc",
   "metadata": {},
   "source": [
    "Запускаем с параметрами теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb591e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ResultPlot(through =['boosting','class_weight'],params= { \n",
    "    'features':  ['learning_rate','max_depth','num_leaves','boosting','class_weight'],\n",
    "    'limits': {'learning_rate': (0, 0.1), 'test_score': (0.25, 0.75)}, \n",
    "    'title': 'Dependency of learning_rate and test_score ',\n",
    "    'figsize': (10, 6)\n",
    "    } )\n",
    "p.add_result(gs.cv_results_,'gradient boosting')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f49e3",
   "metadata": {},
   "source": [
    "И смотрим лучший результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2350a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>boosting</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>test_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>0.548715</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>None</td>\n",
       "      <td>0.547176</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>0.547145</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.539712</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>0.536929</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>0.535684</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>None</td>\n",
       "      <td>0.534573</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.533866</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.532813</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>None</td>\n",
       "      <td>0.531626</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.529086</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.30</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>None</td>\n",
       "      <td>0.522831</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.520450</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>None</td>\n",
       "      <td>0.514751</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.507111</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.506506</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.20</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.504025</td>\n",
       "      <td>gradient boosting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_depth  num_leaves boosting class_weight  test_score  \\\n",
       "1            0.30          8          99     gbdt     balanced    0.552357   \n",
       "13           0.20          8          99     gbdt         None    0.548715   \n",
       "36           0.10          8          99     dart         None    0.547176   \n",
       "11           0.50          8          99     gbdt         None    0.547145   \n",
       "3            0.10          8          99     gbdt     balanced    0.542683   \n",
       "23           0.30          8          99     dart     balanced    0.539712   \n",
       "12           0.30          8          99     gbdt         None    0.536929   \n",
       "14           0.10          8          99     gbdt         None    0.535684   \n",
       "35           0.20          8          99     dart         None    0.534573   \n",
       "0            0.50          8          99     gbdt     balanced    0.533866   \n",
       "26           0.05          8          99     dart     balanced    0.532813   \n",
       "33           0.50          8          99     dart         None    0.531626   \n",
       "25           0.10          8          99     dart     balanced    0.529086   \n",
       "34           0.30          8          99     dart         None    0.522831   \n",
       "22           0.50          8          99     dart     balanced    0.520450   \n",
       "15           0.05          8          99     gbdt         None    0.514751   \n",
       "2            0.20          8          99     gbdt     balanced    0.507111   \n",
       "5            0.03          8          99     gbdt     balanced    0.506506   \n",
       "24           0.20          8          99     dart     balanced    0.504464   \n",
       "4            0.05          8          99     gbdt     balanced    0.504025   \n",
       "\n",
       "                label  \n",
       "1   gradient boosting  \n",
       "13  gradient boosting  \n",
       "36  gradient boosting  \n",
       "11  gradient boosting  \n",
       "3   gradient boosting  \n",
       "23  gradient boosting  \n",
       "12  gradient boosting  \n",
       "14  gradient boosting  \n",
       "35  gradient boosting  \n",
       "0   gradient boosting  \n",
       "26  gradient boosting  \n",
       "33  gradient boosting  \n",
       "25  gradient boosting  \n",
       "34  gradient boosting  \n",
       "22  gradient boosting  \n",
       "15  gradient boosting  \n",
       "2   gradient boosting  \n",
       "5   gradient boosting  \n",
       "24  gradient boosting  \n",
       "4   gradient boosting  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.rf.sort_values(by='test_score',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f4d70",
   "metadata": {},
   "source": [
    "На графике видно, что\n",
    "* оптимальная скорость обучения около 0.1-0.3\n",
    "* алгоритм gbdt немного лучше , чем dart\n",
    "* несбалансированные модели выглядят стабильнее\n",
    "* результат немного колеблется с ростом скорости обучения, что я не могу объяснить "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8058d696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
